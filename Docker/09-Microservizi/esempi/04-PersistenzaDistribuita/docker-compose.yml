version: '3.8'

services:
  # API Gateway
  api-gateway:
    build: ./services/api-gateway
    ports:
      - "8000:8000"
    environment:
      - USER_SERVICE_URL=http://user-service:8001
      - ORDER_SERVICE_URL=http://order-service:8002
      - CATALOG_SERVICE_URL=http://catalog-service:8003
      - ANALYTICS_SERVICE_URL=http://analytics-service:8004
    depends_on:
      - user-service
      - order-service
      - catalog-service
      - analytics-service
    networks:
      - distributed-data

  # User Service - PostgreSQL + Redis
  user-service:
    build: ./services/user-service
    ports:
      - "8001:8001"
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/users_db
      - REDIS_URL=redis://redis:6379
      - KAFKA_BROKERS=kafka:9092
      - EVENT_STORE_URL=tcp://admin:changeit@eventstore:1113
    depends_on:
      - postgres
      - redis
      - kafka
      - eventstore
    networks:
      - distributed-data
    volumes:
      - ./services/user-service/migrations:/app/migrations

  # Order Service - MongoDB + Event Store
  order-service:
    build: ./services/order-service
    ports:
      - "8002:8002"
    environment:
      - MONGODB_URL=mongodb://mongodb:27017/orders_db
      - EVENT_STORE_URL=tcp://admin:changeit@eventstore:1113
      - KAFKA_BROKERS=kafka:9092
      - USER_SERVICE_URL=http://user-service:8001
    depends_on:
      - mongodb
      - eventstore
      - kafka
    networks:
      - distributed-data

  # Catalog Service - Elasticsearch + Redis Cache
  catalog-service:
    build: ./services/catalog-service
    ports:
      - "8003:8003"
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - REDIS_URL=redis://redis:6379
      - KAFKA_BROKERS=kafka:9092
    depends_on:
      - elasticsearch
      - redis
      - kafka
    networks:
      - distributed-data

  # Analytics Service - ClickHouse
  analytics-service:
    build: ./services/analytics-service
    ports:
      - "8004:8004"
    environment:
      - CLICKHOUSE_URL=http://clickhouse:8123
      - KAFKA_BROKERS=kafka:9092
    depends_on:
      - clickhouse
      - kafka
    networks:
      - distributed-data

  # Data Synchronization Service
  sync-service:
    build: ./services/sync-service
    environment:
      - KAFKA_BROKERS=kafka:9092
      - POSTGRES_URL=postgresql://postgres:password@postgres:5432/users_db
      - MONGODB_URL=mongodb://mongodb:27017/orders_db
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - CLICKHOUSE_URL=http://clickhouse:8123
    depends_on:
      - kafka
      - postgres
      - mongodb
      - elasticsearch
      - clickhouse
    networks:
      - distributed-data

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=users_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infrastructure/databases/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./infrastructure/databases/postgres/postgresql.conf:/etc/postgresql/postgresql.conf
    command: ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]
    networks:
      - distributed-data

  # MongoDB Database
  mongodb:
    image: mongo:7.0
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password
      - MONGO_INITDB_DATABASE=orders_db
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
      - ./infrastructure/databases/mongodb/init.js:/docker-entrypoint-initdb.d/init.js
      - ./infrastructure/databases/mongodb/mongod.conf:/etc/mongod.conf
    command: ["mongod", "--config", "/etc/mongod.conf"]
    networks:
      - distributed-data

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - cluster.name=catalog-cluster
      - node.name=catalog-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./infrastructure/databases/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    networks:
      - distributed-data

  # ClickHouse for Analytics
  clickhouse:
    image: clickhouse/clickhouse-server:23.10
    environment:
      - CLICKHOUSE_DB=analytics_db
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=password
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./infrastructure/databases/clickhouse/config.xml:/etc/clickhouse-server/config.xml
      - ./infrastructure/databases/clickhouse/users.xml:/etc/clickhouse-server/users.xml
      - ./infrastructure/databases/clickhouse/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - distributed-data

  # Redis for Caching and Read Models
  redis:
    image: redis:7.2-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./infrastructure/databases/redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
    networks:
      - distributed-data

  # EventStore for Event Sourcing
  eventstore:
    image: eventstore/eventstore:23.10.0-bookworm-slim
    environment:
      - EVENTSTORE_CLUSTER_SIZE=1
      - EVENTSTORE_RUN_PROJECTIONS=All
      - EVENTSTORE_START_STANDARD_PROJECTIONS=true
      - EVENTSTORE_EXT_TCP_PORT=1113
      - EVENTSTORE_HTTP_PORT=2113
      - EVENTSTORE_INSECURE=true
      - EVENTSTORE_ENABLE_EXTERNAL_TCP=true
      - EVENTSTORE_ENABLE_ATOM_PUB_OVER_HTTP=true
    ports:
      - "1113:1113"
      - "2113:2113"
    volumes:
      - eventstore_data:/var/lib/eventstore
      - eventstore_logs:/var/log/eventstore
    networks:
      - distributed-data

  # Apache Kafka for Data Streaming
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - distributed-data

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - distributed-data

  # Kafka Connect for CDC
  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.5.0
    depends_on:
      - kafka
      - postgres
      - mongodb
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: distributed-data-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
    volumes:
      - ./infrastructure/kafka/connect/connectors:/etc/kafka-connect/connectors
    command:
      - bash
      - -c
      - |
        # Install connectors
        confluent-hub install --no-prompt debezium/debezium-connector-postgresql:2.4.0
        confluent-hub install --no-prompt debezium/debezium-connector-mongodb:2.4.0
        confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:14.0.3
        /etc/confluent/docker/run
    networks:
      - distributed-data

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:v2.47.0
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./infrastructure/monitoring/prometheus/rules:/etc/prometheus/rules
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - distributed-data

  grafana:
    image: grafana/grafana:10.2.0
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
      - ./infrastructure/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    networks:
      - distributed-data

  jaeger:
    image: jaegertracing/all-in-one:1.51
    ports:
      - "14268:14268"
      - "16686:16686"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - distributed-data

volumes:
  postgres_data:
  mongodb_data:
  elasticsearch_data:
  clickhouse_data:
  redis_data:
  eventstore_data:
  eventstore_logs:
  zookeeper_data:
  zookeeper_logs:
  kafka_data:
  prometheus_data:
  grafana_data:

networks:
  distributed-data:
    driver: bridge
